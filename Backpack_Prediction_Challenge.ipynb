{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extract the ZIP File"
      ],
      "metadata": {
        "id": "rzgWy4KFsJPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Define paths\n",
        "zip_path = \"/content/playground-series-s5e2.zip\"  # Update if needed\n",
        "extract_path = \"/content/extracted_data\"\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete. Files are available in:\", extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk0Yxa0xsKRM",
        "outputId": "b605634d-f629-410e-dc5c-f6b0bc2ec9ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete. Files are available in: /content/extracted_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data"
      ],
      "metadata": {
        "id": "VS4BYBcwsOHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/extracted_data/train.csv\"  # Update if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display dataset info and first 5 rows\n",
        "print(df.info())\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8ws3bM9sVDC",
        "outputId": "bba198f4-8d4b-4aa2-bbd3-773b257321a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300000 entries, 0 to 299999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   id                    300000 non-null  int64  \n",
            " 1   Brand                 290295 non-null  object \n",
            " 2   Material              291653 non-null  object \n",
            " 3   Size                  293405 non-null  object \n",
            " 4   Compartments          300000 non-null  float64\n",
            " 5   Laptop Compartment    292556 non-null  object \n",
            " 6   Waterproof            292950 non-null  object \n",
            " 7   Style                 292030 non-null  object \n",
            " 8   Color                 290050 non-null  object \n",
            " 9   Weight Capacity (kg)  299862 non-null  float64\n",
            " 10  Price                 300000 non-null  float64\n",
            "dtypes: float64(3), int64(1), object(7)\n",
            "memory usage: 25.2+ MB\n",
            "None\n",
            "   id         Brand Material    Size  Compartments Laptop Compartment  \\\n",
            "0   0      Jansport  Leather  Medium           7.0                Yes   \n",
            "1   1      Jansport   Canvas   Small          10.0                Yes   \n",
            "2   2  Under Armour  Leather   Small           2.0                Yes   \n",
            "3   3          Nike    Nylon   Small           8.0                Yes   \n",
            "4   4        Adidas   Canvas  Medium           1.0                Yes   \n",
            "\n",
            "  Waterproof      Style  Color  Weight Capacity (kg)      Price  \n",
            "0         No       Tote  Black             11.611723  112.15875  \n",
            "1        Yes  Messenger  Green             27.078537   68.88056  \n",
            "2         No  Messenger    Red             16.643760   39.17320  \n",
            "3         No  Messenger  Green             12.937220   80.60793  \n",
            "4        Yes  Messenger  Green             17.749338   86.02312  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handle Missing Values"
      ],
      "metadata": {
        "id": "5ayoqBB7sW9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing categorical values with \"Unknown\"\n",
        "categorical_cols = [\"Brand\", \"Material\", \"Size\", \"Laptop Compartment\", \"Waterproof\", \"Style\", \"Color\"]\n",
        "df[categorical_cols] = df[categorical_cols].fillna(\"Unknown\")\n",
        "\n",
        "# Fill missing numerical values with median\n",
        "numerical_cols = [\"Weight Capacity (kg)\"]\n",
        "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
        "\n",
        "print(\"Missing values handled.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6yQRa13sY-t",
        "outputId": "ea10a9d5-d5e2-43ac-da1e-560db69bca4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values handled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encode Categorical Variables"
      ],
      "metadata": {
        "id": "7YzYdJJlscNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform one-hot encoding for categorical columns\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(\"Categorical encoding complete. New shape:\", df_encoded.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB1KcaJ1sedL",
        "outputId": "b61a2241-f76c-4bf4-dac0-764e3007fce8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical encoding complete. New shape: (300000, 29)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data for Training & Testing"
      ],
      "metadata": {
        "id": "99P0NCjesyyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features and target\n",
        "X = df_encoded.drop(columns=[\"id\", \"Price\"])\n",
        "y = df_encoded[\"Price\"]\n",
        "\n",
        "# Split data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data split complete. Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBjyi1lIs07W",
        "outputId": "bee9736d-2539-41b0-be21-03defa22d6c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split complete. Train shape: (240000, 27) Test shape: (60000, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a Machine Learning Model"
      ],
      "metadata": {
        "id": "aEjvoVm-s6Sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f\"Model Training Complete! Mean Absolute Error: {mae:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbEKFmmks7LJ",
        "outputId": "b24a822c-9b94-42bc-b2fc-0efd8016e351"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Training Complete! Mean Absolute Error: 34.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Model"
      ],
      "metadata": {
        "id": "SQgsK163uCqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, \"backpack_price_predictor.pkl\")\n",
        "print(\"Model saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXC6uNiEuExF",
        "outputId": "0048a28a-211e-4bdd-eaae-500c992d99cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Test Data (Kaggle Test Set)"
      ],
      "metadata": {
        "id": "JEsNaREguNTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test dataset (Replace with the actual test file path)\n",
        "test_file_path = \"/content/extracted_data/test.csv\"  # Update if needed\n",
        "test_df = pd.read_csv(test_file_path)\n",
        "\n",
        "# Display test dataset info\n",
        "print(test_df.info())\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCl-uEzRub0K",
        "outputId": "0302cd68-af32-4197-aeec-9b9f878fbeaf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 10 columns):\n",
            " #   Column                Non-Null Count   Dtype  \n",
            "---  ------                --------------   -----  \n",
            " 0   id                    200000 non-null  int64  \n",
            " 1   Brand                 193773 non-null  object \n",
            " 2   Material              194387 non-null  object \n",
            " 3   Size                  195619 non-null  object \n",
            " 4   Compartments          200000 non-null  float64\n",
            " 5   Laptop Compartment    195038 non-null  object \n",
            " 6   Waterproof            195189 non-null  object \n",
            " 7   Style                 194847 non-null  object \n",
            " 8   Color                 193215 non-null  object \n",
            " 9   Weight Capacity (kg)  199923 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(7)\n",
            "memory usage: 15.3+ MB\n",
            "None\n",
            "       id   Brand Material    Size  Compartments Laptop Compartment  \\\n",
            "0  300000    Puma  Leather   Small           2.0                 No   \n",
            "1  300001    Nike   Canvas  Medium           7.0                 No   \n",
            "2  300002  Adidas   Canvas   Large           9.0                 No   \n",
            "3  300003  Adidas    Nylon   Large           1.0                Yes   \n",
            "4  300004     NaN    Nylon   Large           2.0                Yes   \n",
            "\n",
            "  Waterproof      Style  Color  Weight Capacity (kg)  \n",
            "0         No       Tote  Green             20.671147  \n",
            "1        Yes   Backpack  Green             13.564105  \n",
            "2        Yes  Messenger   Blue             11.809799  \n",
            "3         No  Messenger  Green             18.477036  \n",
            "4        Yes       Tote  Black              9.907953  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the Test Data"
      ],
      "metadata": {
        "id": "ccE79tOeugjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in test set\n",
        "test_df[categorical_cols] = test_df[categorical_cols].fillna(\"Unknown\")\n",
        "test_df[numerical_cols] = test_df[numerical_cols].fillna(df[numerical_cols].median())\n",
        "\n",
        "# Apply the same encoding as training data\n",
        "test_df_encoded = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Ensure test data has the same columns as training data\n",
        "missing_cols = set(X_train.columns) - set(test_df_encoded.columns)\n",
        "for col in missing_cols:\n",
        "    test_df_encoded[col] = 0  # Add missing columns with value 0\n",
        "\n",
        "# Ensure correct column order\n",
        "test_df_encoded = test_df_encoded[X_train.columns]\n",
        "\n",
        "print(\"Test data preprocessing complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huYZjWRVuiwr",
        "outputId": "70561fdd-dff1-4ad1-c3bc-2ca160538a36"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data preprocessing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make Predictions"
      ],
      "metadata": {
        "id": "tEoO_f-Euns8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict backpack prices\n",
        "test_df[\"Price\"] = model.predict(test_df_encoded)\n",
        "\n",
        "# Select required columns\n",
        "submission = test_df[[\"id\", \"Price\"]]\n",
        "\n",
        "print(\"Predictions complete. Preview:\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmVwLEy-upnn",
        "outputId": "73255662-408c-4b1e-9888-f28e8c66050d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions complete. Preview:\n",
            "       id      Price\n",
            "0  300000  77.731506\n",
            "1  300001  82.134377\n",
            "2  300002  79.730793\n",
            "3  300003  68.417504\n",
            "4  300004  72.907070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Predictions as submission.csv"
      ],
      "metadata": {
        "id": "oQQR4MIJuxqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the file\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission.csv saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92kqGVttu0Dg",
        "outputId": "cfea79f9-ecbc-4a4f-96b5-3e184ee900e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "submission.csv saved successfully.\n"
          ]
        }
      ]
    }
  ]
}